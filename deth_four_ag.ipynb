{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64dfe616",
   "metadata": {},
   "source": [
    "# Four on one row Agent\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis vestibulum, nibh sit amet convallis varius, neque arcu luctus nunc, gravida sollicitudin quam nisi mattis ante. Duis imperdiet lorem a pharetra iaculis. In hac habitasse platea dictumst. Vivamus nisl ex, semper eget facilisis vel, varius ac est. Curabitur eget nisl erat. In egestas molestie mi, a pulvinar ante sodales sit amet. Vivamus interdum sem eu interdum placerat. Duis tempus purus non lectus pharetra, ac gravida mauris ultricies. Vestibulum condimentum ut dolor nec interdum. Curabitur et ex magna. In erat purus, laoreet vitae elementum sed, vehicula eu lorem. Nulla maximus eu est vel tempor. Ut et aliquam quam, eu pellentesque leo. Ut at suscipit eros. Phasellus luctus, justo nec molestie pharetra, massa sem hendrerit arcu, ut ullamcorper justo augue et est. Donec dictum sem id tristique pharetra.\n",
    "\n",
    "#TODO state which libaries are used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811a4e2",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "... \n",
    "\n",
    "#TODO fix this!\n",
    "This notebook defines an agent for the game four on one row, against 2 opponents. The first opponent randomly picks his actions, the second opponnent.... (still has to be defined).\n",
    "The agent marks his spots using R, the opponent marks his stops using Y.\n",
    "\n",
    "The game will be played on a field sized 5x5.\n",
    "\n",
    "States: The environment has 25 states, S1 representing the top left spot and S25 representing the bottom right spot.\n",
    "Actions:\n",
    "Transitions:\n",
    "\n",
    "- States: The Environment is in one of the following states $S = (S_0, S_1, ..., S_25)$ with $S_i \\in \\{E, R, Y\\}$ (E represents an empty spot) .\n",
    "\n",
    "\n",
    "- Actions: The set of available actions is $a \\in \\{n \\in \\mathbb{N}: S_n = E \\land S_n-5 \\neq  E  \\}$ (the agent can place the X on any empty place with a surface)\n",
    "\n",
    "\n",
    "- Transitions: \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12f32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import FourInARowEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3c6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = FourInARowEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627ce832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   │   │   │   │   │   │   \n",
      "───┼───┼───┼───┼───┼───┼───\n",
      "   │   │   │   │   │   │   \n",
      "───┼───┼───┼───┼───┼───┼───\n",
      "   │   │   │   │   │   │   \n",
      "───┼───┼───┼───┼───┼───┼───\n",
      "   │   │   │   │   │   │   \n",
      "───┼───┼───┼───┼───┼───┼───\n",
      "   │   │   │   │   │   │   \n",
      "───┼───┼───┼───┼───┼───┼───\n",
      "   │   │   │   │   │   │   \n"
     ]
    }
   ],
   "source": [
    "print(environment.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749d0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from random import randint, choice\n",
    "from copy import copy\n",
    "\n",
    "E, X, O = ' ', 'X', 'O'\n",
    "\n",
    "class TicTacToeMDPEnvironment():\n",
    "    def __init__(self, initial_state=None):\n",
    "        if initial_state == None:\n",
    "            self.__initial_state = [E for n in range(9)]  # start with empty board\n",
    "        else:\n",
    "            self.__initial_state = copy(initial_state)  # copy to prevent aliassing\n",
    "        self.__state = self.__initial_state\n",
    "        self.__possible_states = []\n",
    "        self.__calculate_possible_states(self.__initial_state)\n",
    "        \n",
    "    def __calculate_possible_states(self, state):\n",
    "        actions = self.get_possible_actions(state)\n",
    "        for action in actions:\n",
    "            new_state = copy(state)\n",
    "            if state.count(X) == state.count(O):\n",
    "                new_state[action] = X \n",
    "            else: \n",
    "                new_state[action] = O\n",
    "            self.__possible_states.append(new_state)\n",
    "            if not self.is_done(new_state):\n",
    "                self.__calculate_possible_states(new_state)\n",
    "\n",
    "    def reset(self):\n",
    "        self.__state = self.__initial_state\n",
    "        return self.__state\n",
    "    \n",
    "    def __calculate_transition(self, action):\n",
    "        # change the state to reflect the move by the agent\n",
    "        self.__state[action] = X\n",
    "        if self.is_done():\n",
    "            return self.__state\n",
    "        # let the opponent make a random move\n",
    "        opponent_action = choice(self.get_possible_actions())\n",
    "        self.__state[opponent_action] = O\n",
    "        return self.__state\n",
    "      \n",
    "    def step(self, action):\n",
    "        old_state = self.__state\n",
    "        self.__state = self.__calculate_transition(action)  # state after action\n",
    "        observation = self.__state  # environment is fully observable\n",
    "        done = self.is_done()\n",
    "        reward = self.get_reward(self.__state)\n",
    "        info = {}  # optional debug info\n",
    "        return observation, done, reward, info\n",
    "\n",
    "    def render(self):\n",
    "        BACKGROUND = [\n",
    "            '   │   │   ',\n",
    "            '───┼───┼───',\n",
    "            '   │   │   ',\n",
    "            '───┼───┼───',\n",
    "            '   │   │   '\n",
    "        ]\n",
    "        rendering = copy(BACKGROUND)\n",
    "        for n, S_n in enumerate(self.__state):\n",
    "            if S_n != E:\n",
    "                row = 2 * (n // 3)\n",
    "                col = 4 * (n % 3) + 1\n",
    "                line = rendering[row]\n",
    "                rendering[row] = line[:col] + S_n + line[col + 1:]\n",
    "        \n",
    "        for line in rendering:\n",
    "            print(line)\n",
    "        \n",
    "    #=========================================================\n",
    "    # public functions for agent to calculate optimal policy\n",
    "    #=========================================================\n",
    "    \n",
    "    def get_possible_states(self):\n",
    "        return self.__possible_states\n",
    "    \n",
    "    def get_possible_actions(self, state=None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "        return [n for n in range(9) if state[n] == E]\n",
    "\n",
    "    def is_done(self, state=None):\n",
    "        if state is None:\n",
    "            state = self.__state\n",
    "        if E not in state:\n",
    "            return True\n",
    "        if state[0] == state[1] == state[2] != E:\n",
    "            return True\n",
    "        if state[3] == state[4] == state[5] != E:\n",
    "            return True\n",
    "        if state[6] == state[7] == state[8] != E:\n",
    "            return True\n",
    "        if state[0] == state[3] == state[6] != E:\n",
    "            return True\n",
    "        if state[1] == state[4] == state[7] != E:\n",
    "            return True\n",
    "        if state[2] == state[5] == state[8] != E:\n",
    "            return True\n",
    "        if state[0] == state[4] == state[8] != E:\n",
    "            return True\n",
    "        if state[2] == state[4] == state[6] != E:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_reward(self, state):\n",
    "        # Reward R(s) for every possible state\n",
    "        if state[0] == state[1] == state[2] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[3] == state[4] == state[5] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[6] == state[7] == state[8] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[0] == state[3] == state[6] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[1] == state[4] == state[7] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[2] == state[5] == state[8] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[0] == state[4] == state[8] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        if state[2] == state[4] == state[6] != E:\n",
    "            return 1 if state[0] == X else -1\n",
    "        return False\n",
    "        \n",
    "    def get_transition_prob(self, action, new_state, old_state=None):\n",
    "        if old_state is None:\n",
    "            old_state = self.__state\n",
    "        # returns the Transition Probability P(s'| s, a)\n",
    "        # with s = old_state, a = action and s' = new_state\n",
    "\n",
    "        # if the game is over, no transition can take place\n",
    "        if self.is_done(old_state):\n",
    "            return 0.0\n",
    "        \n",
    "        # the position of the action must be empty\n",
    "        if old_state[action] != E:\n",
    "            return 0.0\n",
    "        \n",
    "        # state after placing X\n",
    "        state_after_X = copy(old_state)  # avoid unwanted changed by reference\n",
    "        state_after_X[action] = X\n",
    "\n",
    "        # check if game is done\n",
    "        if self.is_done(state_after_X) and state_after_X == new_state:\n",
    "            return 1.0\n",
    "\n",
    "        # game is not done: calculate all possible states of the opponent\n",
    "        possible_new_states = []\n",
    "        possible_opponent_actions = self.get_possible_actions(state_after_X)\n",
    "        for action in possible_opponent_actions:\n",
    "            possible_new_state = copy(state_after_X)\n",
    "            possible_new_state[action] = O\n",
    "            possible_new_states.append(possible_new_state)\n",
    "        if new_state not in possible_new_states:\n",
    "            return 0.0\n",
    "        \n",
    "        # transition is possible, apply strategy:\n",
    "        # random opponent, probability is 1 / (# of E before placing the new O)\n",
    "        prob = 1 / (len(possible_new_states))\n",
    "        return prob\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
