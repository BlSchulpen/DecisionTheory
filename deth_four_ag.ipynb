{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6896d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dfe616",
   "metadata": {},
   "source": [
    "# Four in a row Agent and Environment\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis vestibulum, nibh sit amet convallis varius, neque arcu luctus nunc, gravida sollicitudin quam nisi mattis ante. Duis imperdiet lorem a pharetra iaculis. In hac habitasse platea dictumst. Vivamus nisl ex, semper eget facilisis vel, varius ac est. Curabitur eget nisl erat. In egestas molestie mi, a pulvinar ante sodales sit amet. Vivamus interdum sem eu interdum placerat. Duis tempus purus non lectus pharetra, ac gravida mauris ultricies. Vestibulum condimentum ut dolor nec interdum. Curabitur et ex magna. In erat purus, laoreet vitae elementum sed, vehicula eu lorem. Nulla maximus eu est vel tempor. Ut et aliquam quam, eu pellentesque leo. Ut at suscipit eros. Phasellus luctus, justo nec molestie pharetra, massa sem hendrerit arcu, ut ullamcorper justo augue et est. Donec dictum sem id tristique pharetra.\n",
    "\n",
    "#TODO state which libaries are used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811a4e2",
   "metadata": {},
   "source": [
    "## 1. Definition of the Environment\n",
    "\n",
    "- States: The environment is in one of the following states $S = (S_0, S_1, ..., S_w)$ with $S_x = (S_{x0}, S_{x1}, ..., S_{xh})$ and $S_{xy} \\in \\{E, R, Y\\}$.\n",
    "- Actions: The set of  available actions: $a \\in \\{n \\in \\mathbb{N}: (|E \\in S_n| > 0)\\}$ (the agent can place their chip in any non-full column).\n",
    "- Transitions: The transition depends on the opponent's strategy. If we assume the opponent plays randomly then the probability of them picking a viable column is $\\dfrac{1}{nr\\;of\\;valid\\;columns}$\n",
    "\n",
    "The `FourInARowEnv` class has the following methods:\n",
    "- `reset()` resets the environment's state to it's initial state.\n",
    "- `step(action)` processes the action of the agent.\n",
    "- `render()` displays the state using box characters.\n",
    "\n",
    "To allow an agent to calculate optimal decisions using model information, these methods are also available:\n",
    "- `get_possible_states()` calculates all possible future states.\n",
    "- `is_done()` checks if there is a winner of if the board is full.\n",
    "- `get_reward_for_new(state)` simplified version $R(s)$ of the general reward function: $R(s, a, s')$.\n",
    "- `get_transition_prob(action, new_state, old_state)` $P(s' \\mid s, a)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec035b",
   "metadata": {},
   "source": [
    "## 2. Environment Creation\n",
    "\n",
    "We are able to create an environment with several parameters:\n",
    "\n",
    "- `yellow_agent` is used to define an agent that will act as the opponent.\n",
    "- `width` the width of the playing field.\n",
    "- `height` the height of the playing field.\n",
    "- `win_conditions` the number of chips in a row required to win.\n",
    "- `first_turn` the player that will play first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a12f32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import FourInARowEnv, FourInARowRandomAgent, Players, render_multiple_states, BoxState, FourInARowRenderer, FourInARowMinMaxAgent, FourInARowValueIterationAgent,FourInARowGraphCreator\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7e3c6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987af686",
   "metadata": {},
   "source": [
    "### 2.1 Displaying the board\n",
    "\n",
    "The board is displayed using box characters. The letter `Y` represents a yellow chip, and the letter `R` represents a red one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "260dddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐\n",
      "│   │   │   │\n",
      "├───┼───┼───┤\n",
      "│   │   │   │\n",
      "├───┼───┼───┤\n",
      "│   │ Y │ R │\n",
      "└───┴───┴───┘\n"
     ]
    }
   ],
   "source": [
    "red_agent = FourInARowRandomAgent(environment)\n",
    "\n",
    "environment.step(red_agent.get_move())\n",
    "\n",
    "print(environment.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5407e8",
   "metadata": {},
   "source": [
    "## 3. Actions and probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb13f0",
   "metadata": {},
   "source": [
    "### 3.1 Possible states and actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a17961dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │ R │   │   │ │ R │   │   │ │ R │   │   │ │ R │ Y │   │ │ R │ Y │   │ │ R │   │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │ Y │   │   │ │ Y │   │   │ │ Y │   │   │ │ Y │ R │   │ │ Y │ R │   │ │ Y │ R │   │ │ Y │ R │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│ R │   │   │ │ R │   │   │ │ R │   │   │ │ R │ Y │   │ │ R │ Y │   │ │ R │ Y │   │ │ R │ Y │ R │ │ R │ Y │ Y │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      " a: [0, 1, 2]  a: [0, 1, 2]  a: [1, 2]     a: [1, 2]     a: [1, 2]     a: [2]        a: [2]        a: [1, 2]   \n",
      " f: False      f: False      f: False      f: False      f: False      f: False      f: True       f: False    \n",
      "\n",
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│ R │ R │   │ │ R │ R │   │ │ R │ R │ R │ │ R │   │   │ │ R │ Y │   │ │ R │ Y │ R │ │ R │   │ Y │ │ R │ R │ Y │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│ Y │ R │   │ │ Y │ R │ Y │ │ Y │ R │ Y │ │ Y │ R │ R │ │ Y │ R │ R │ │ Y │ R │ R │ │ Y │ R │ R │ │ Y │ R │ R │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      " a: [2]        a: [2]        a: []         a: [1, 2]     a: [2]        a: []         a: [1]        a: []       \n",
      " f: False      f: False      f: True       f: False      f: False      f: True       f: False      f: True     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environment.reset()\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = environment.get_possible_states()[0:16], \n",
    "  columns         = 8, \n",
    "  additional_info = lambda s: f'a: {environment.get_possible_actions(s)}\\nf: {s.is_finished()}'\n",
    ")\n",
    "\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2224d21",
   "metadata": {},
   "source": [
    "### 3.2 Transition probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "627ce832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state:\n",
      "┌───┬───┐\n",
      "│   │   │\n",
      "├───┼───┤\n",
      "│   │   │\n",
      "└───┴───┘\n",
      "\n",
      "New state:\n",
      "┌───┬───┐ ┌───┬───┐ ┌───┬───┐ ┌───┬───┐\n",
      "│ Y │   │ │   │   │ │ Y │   │ │   │ Y │\n",
      "├───┼───┤ ├───┼───┤ ├───┼───┤ ├───┼───┤\n",
      "│ R │   │ │ R │ Y │ │ R │   │ │ R │   │\n",
      "└───┴───┘ └───┴───┘ └───┴───┘ └───┴───┘\n",
      " Action 0  Action 0  Action 0  Action 0\n",
      " p: 0.5    p: 0.5    p: 0.5    p: 0.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 2,\n",
    "  height        = 2,\n",
    "  win_condition = 2,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "s0 = deepcopy(env._state)\n",
    "s1 = deepcopy(s0)\n",
    "s1._grid = [\n",
    "  [BoxState.RED   , BoxState.YELLOW],\n",
    "  [BoxState.EMPTY , BoxState.EMPTY ]\n",
    "]\n",
    "s2 = deepcopy(s0)\n",
    "s2._grid = [\n",
    "  [BoxState.RED   , BoxState.EMPTY],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY]\n",
    "]\n",
    "s3 = deepcopy(s0)\n",
    "s3._grid = [\n",
    "  [BoxState.RED    , BoxState.YELLOW],\n",
    "  [BoxState.EMPTY  , BoxState.EMPTY ]\n",
    "]\n",
    "s4 = deepcopy(s0)\n",
    "s4._grid = [\n",
    "  [BoxState.RED    , BoxState.EMPTY ],\n",
    "  [BoxState.EMPTY  , BoxState.YELLOW]\n",
    "]\n",
    "\n",
    "print('Start state:')\n",
    "print(FourInARowRenderer(s0).render())\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = [s1, s2, s3, s4],\n",
    "  columns         = 8,\n",
    "  additional_info = lambda s: f'Action 0\\np: {round(env.get_transition_prob(0, s, s0), 2)}'\n",
    ")\n",
    "\n",
    "print('\\nNew state:')\n",
    "print(display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8f161cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state:\n",
      "┌───┬───┐\n",
      "│   │   │\n",
      "├───┼───┤\n",
      "│ R │ Y │\n",
      "└───┴───┘\n",
      "\n",
      "New state:\n",
      "┌───┬───┐ ┌───┬───┐\n",
      "│ R │   │ │ R │ Y │\n",
      "├───┼───┤ ├───┼───┤\n",
      "│ R │ Y │ │ R │ Y │\n",
      "└───┴───┘ └───┴───┘\n",
      " Action 0  Action 0\n",
      " p: 1.0    p: 0.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 2,\n",
    "  height        = 2,\n",
    "  win_condition = 2,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "s0 = deepcopy(env._state)\n",
    "s0._grid = [\n",
    "  [BoxState.RED   , BoxState.EMPTY ],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY ]\n",
    "]\n",
    "s1 = deepcopy(s0)\n",
    "s1._grid = [\n",
    "  [BoxState.RED   , BoxState.RED],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY ]\n",
    "]\n",
    "s2 = deepcopy(s0)\n",
    "s2._grid = [\n",
    "  [BoxState.RED   , BoxState.RED   ],\n",
    "  [BoxState.YELLOW, BoxState.YELLOW]\n",
    "]\n",
    "\n",
    "print('Start state:')\n",
    "print(FourInARowRenderer(s0).render())\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = [s1, s2],\n",
    "  columns         = 8,\n",
    "  additional_info = lambda s: f'Action 0\\np: {round(env.get_transition_prob(0, s, s0), 2)}'\n",
    ")\n",
    "\n",
    "print('\\nNew state:')\n",
    "print(display)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3b61a",
   "metadata": {},
   "source": [
    "### 3.3 Rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d6e65",
   "metadata": {},
   "source": [
    "## 4. Value Iteration\n",
    "\n",
    "Value Iteration is based on the Bellman update:\n",
    "\n",
    "(6) $U_{i+1}(s) = \\underset{a}{max} \\sum_{s'} P(s' \\mid s, a) \\space [ R(s, a, s') + \\gamma \\space U_i(s') ]$\n",
    "\n",
    "Using equation (3) this simplifies to:\n",
    "\n",
    "(7) $U_{i+1}(s) = \\underset{a}{max} \\space Q_i(s, a)$\n",
    "\n",
    "One can prove that after enough iterations $U_{i+1}(s) \\approx U(s)$, after which Bellman's equation is satisfied.  \n",
    "Since there is only one solution to Bellman's equation, it does not matter with which $U_0(s)$ you start!\n",
    "\n",
    "The algorithm below is Value Iteration with one simplification: $\\gamma$ the so-called discount factor, is set to 1.\n",
    "\n",
    "\n",
    "help...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0b7fe6e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24392/2477676252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFourInARowValueIterationAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowValueIterationAgent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, env, error)\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFourInARowEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowValueIterationAgent.py\u001b[0m in \u001b[0;36mvalue_iteration\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mvalue_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mutility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_utility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mdelta\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowValueIterationAgent.py\u001b[0m in \u001b[0;36mget_initial_utility\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_possible_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m       \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_grid_as_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reward_for_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowEnv.py\u001b[0m in \u001b[0;36mget_reward_for_state\u001b[1;34m(self, state, player)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_reward_for_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFourInARowState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPlayers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mwinner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_winner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mwinner\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowState.py\u001b[0m in \u001b[0;36mget_winner\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mhorizontal_winner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_horizontal_win\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mvertical_winner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vertical_win\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mdiagonal_winner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_diagonal_win\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhorizontal_winner\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowState.py\u001b[0m in \u001b[0;36m_check_diagonal_win\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m       \u001b[0mresult_flipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_section_for_win\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflipped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mresult_flipped\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult_flipped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdiagonal\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_diagonal_dispatcher\u001b[1;34m(a, offset, axis1, axis2)\u001b[0m\n\u001b[0;32m   1509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_diagonal_dispatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "\n",
    "agent = FourInARowValueIterationAgent(env)\n",
    "\n",
    "states = []\n",
    "states.append(deepcopy(env.get_state()))\n",
    "while not env.is_done():\n",
    "  env.step(agent.get_move())\n",
    "  states.append(deepcopy(env.get_state()))\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states = states,\n",
    "  columns = 8,\n",
    "  additional_info = lambda _: ''\n",
    ")\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │   │   │   │ │   │ Y │   │ │   │ Y │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │   │   │ │   │   │ R │ │   │ R │ R │ │ R │ R │ R │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │ R │   │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      "                                                                     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "\n",
    "agent = FourInARowMinMaxAgent(env)\n",
    "\n",
    "states = []\n",
    "states.append(deepcopy(env.get_state()))\n",
    "while not env.is_done():\n",
    "  env.step(agent.get_move())\n",
    "  states.append(deepcopy(env.get_state()))\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states = states,\n",
    "  columns = 8,\n",
    "  additional_info = lambda _: ''\n",
    ")\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "66c5baaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FourInARowEnv' object has no attribute 'get_reward_for_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24392/1329253291.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcreator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFourInARowGraphCreator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcreator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_graph_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowGraphCreator.py\u001b[0m in \u001b[0;36mcreate_graph_game\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstart_agent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magent_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mend_agent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0magent_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay_game\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowGraphCreator.py\u001b[0m in \u001b[0;36mplay_game\u001b[1;34m(self, opponent_type, personal_type)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mmain_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersonal_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_winner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mnr_wins\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowSemiRandomAgent.py\u001b[0m in \u001b[0;36mget_move\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no possible moves available'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_actions\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reward_for_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bram\\Documents\\GitHub\\DecisionTheory\\src\\FourInARowSemiRandomAgent.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no possible moves available'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_actions\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reward_for_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FourInARowEnv' object has no attribute 'get_reward_for_action'"
     ]
    }
   ],
   "source": [
    "from src import FourInARowEnv,FourInARowSemiRandomAgent ,FourInARowRandomAgent, Players, render_multiple_states, BoxState, FourInARowRenderer, FourInARowMinMaxAgent, FourInARowValueIterationAgent,FourInARowGraphCreator\n",
    "agent_types = [FourInARowRandomAgent,FourInARowSemiRandomAgent] \n",
    "creator = FourInARowGraphCreator()\n",
    "\n",
    "creator.create_graph_game()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1932237d5f6e1407a57ef8cc07d4a91480fed45ce28e9b3cad897d61089d0e1"
  },
  "kernelspec": {
   "display_name": "PyCharm (DecisionTheory)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "%load_ext autoreload\n",
     "%autoreload 2\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
