{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6896d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dfe616",
   "metadata": {},
   "source": [
    "# Four in a row Agent and Environment\n",
    "\n",
    "This is an implementation of a rational agents for the game four in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811a4e2",
   "metadata": {},
   "source": [
    "## 1. Definition of the Environment\n",
    "\n",
    "- States: The environment is in one of the following states $S = (S_0, S_1, ..., S_w)$ with $S_x = (S_{x,0}, S_{x,1}, ..., S_{x,h})$ and $S_{x,y} \\in \\{E, R, Y\\}$.\n",
    "- Actions: The set of  available actions: $a \\in \\{n \\in \\mathbb{N}: (|E \\in S_n| > 0)\\}$ (the agent can place their chip in any non-full column).\n",
    "- Transitions: The transition depends on the opponent's strategy. If we assume the opponent plays randomly then the probability of them picking a viable column is $\\dfrac{1}{nr\\;of\\;valid\\;columns}$\n",
    "\n",
    "The `FourInARowEnv` class has the following methods:\n",
    "- `reset()` resets the environment's state to it's initial state.\n",
    "- `step(action)` processes the action of the agent.\n",
    "- `render()` displays the state using box characters.\n",
    "- `get_state()` returns the current state.\n",
    "- `is_done()` checks if there is a winner of if the board is full.\n",
    "\n",
    "To allow an agent to calculate optimal decisions using model information, these methods are also available:\n",
    "- `get_possible_states()` calculates all possible future states.\n",
    "- `get_reward_for_state(state)` simplified version $R(s)$ of the general reward function: $R(s, a, s')$.\n",
    "- `get_transition_prob(action, new_state, old_state)` $P(s' \\mid s, a)$.\n",
    "- `get_possible_actions(action)` returns the possible actions.\n",
    "- `get_possible_states_after_action(action)` calculates the possible states after an action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19188f",
   "metadata": {},
   "source": [
    "### 1.1 Definition of an agent\n",
    "\n",
    "Agents have access to the environment they play in and what player they play as. An agent has only 1 method named `get_move`. `get_move` is responsible for calculating the optimal action and returning it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec035b",
   "metadata": {},
   "source": [
    "## 2. Environment Creation\n",
    "\n",
    "We are able to create an environment with several parameters:\n",
    "\n",
    "- `yellow_agent` is used to define an agent that will act as the opponent.\n",
    "- `width` the width of the playing field.\n",
    "- `height` the height of the playing field.\n",
    "- `win_conditions` the number of chips in a row required to win.\n",
    "- `first_turn` the player that will play first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a12f32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import FourInARowEnv, Players, render_multiple_states, BoxState, FourInARowRenderer,FourInARowGraphCreator\n",
    "from src.agents import FourInARowRandomAgent, FourInARowMinMaxAgent, FourInARowValueIterationAgent, FourInARowSemiRandomAgent\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e3c6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987af686",
   "metadata": {},
   "source": [
    "### 2.1 Displaying the board\n",
    "\n",
    "The board is displayed using box characters. The letter `Y` represents a yellow chip, and the letter `R` represents a red one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "260dddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐\n",
      "│   │   │   │\n",
      "├───┼───┼───┤\n",
      "│   │   │   │\n",
      "├───┼───┼───┤\n",
      "│ R │ Y │   │\n",
      "└───┴───┴───┘\n"
     ]
    }
   ],
   "source": [
    "red_agent = FourInARowRandomAgent(environment)\n",
    "\n",
    "environment.step(red_agent.get_move())\n",
    "\n",
    "print(environment.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5407e8",
   "metadata": {},
   "source": [
    "## 3. Actions and probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb13f0",
   "metadata": {},
   "source": [
    "### 3.1 Possible states and actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a17961dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │ R │   │   │ │ R │   │   │ │ R │   │   │ │ R │ Y │   │ │ R │ Y │   │ │ R │   │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │ Y │   │   │ │ Y │   │   │ │ Y │   │   │ │ Y │ R │   │ │ Y │ R │   │ │ Y │ R │   │ │ Y │ R │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│ R │   │   │ │ R │   │   │ │ R │   │   │ │ R │ Y │   │ │ R │ Y │   │ │ R │ Y │   │ │ R │ Y │ R │ │ R │ Y │ Y │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      " a: [0, 1, 2]  a: [0, 1, 2]  a: [1, 2]     a: [1, 2]     a: [1, 2]     a: [2]        a: [2]        a: [1, 2]   \n",
      " f: False      f: False      f: False      f: False      f: False      f: False      f: True       f: False    \n",
      "\n",
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│ R │ R │   │ │ R │ R │   │ │ R │ R │ R │ │ R │   │   │ │ R │ Y │   │ │ R │ Y │ R │ │ R │   │ Y │ │ R │ R │ Y │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│ Y │ R │   │ │ Y │ R │ Y │ │ Y │ R │ Y │ │ Y │ R │ R │ │ Y │ R │ R │ │ Y │ R │ R │ │ Y │ R │ R │ │ Y │ R │ R │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      " a: [2]        a: [2]        a: []         a: [1, 2]     a: [2]        a: []         a: [1]        a: []       \n",
      " f: False      f: False      f: True       f: False      f: False      f: True       f: False      f: True     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "environment.reset()\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = environment.get_possible_states()[0:16], \n",
    "  columns         = 8, \n",
    "  additional_info = lambda s: f'a: {environment.get_possible_actions(s)}\\nf: {s.is_finished()}'\n",
    ")\n",
    "\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2224d21",
   "metadata": {},
   "source": [
    "### 3.2 Transition probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "627ce832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state:\n",
      "┌───┬───┐\n",
      "│   │   │\n",
      "├───┼───┤\n",
      "│   │   │\n",
      "└───┴───┘\n",
      "\n",
      "New state:\n",
      "┌───┬───┐ ┌───┬───┐ ┌───┬───┐ ┌───┬───┐\n",
      "│ Y │   │ │   │   │ │ Y │   │ │   │ Y │\n",
      "├───┼───┤ ├───┼───┤ ├───┼───┤ ├───┼───┤\n",
      "│ R │   │ │ R │ Y │ │ R │   │ │ R │   │\n",
      "└───┴───┘ └───┴───┘ └───┴───┘ └───┴───┘\n",
      " Action 0  Action 0  Action 0  Action 0\n",
      " p: 0.5    p: 0.5    p: 0.5    p: 0.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 2,\n",
    "  height        = 2,\n",
    "  win_condition = 2,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "s0 = deepcopy(env._state)\n",
    "s1 = deepcopy(s0)\n",
    "s1._grid = [\n",
    "  [BoxState.RED   , BoxState.YELLOW],\n",
    "  [BoxState.EMPTY , BoxState.EMPTY ]\n",
    "]\n",
    "s2 = deepcopy(s0)\n",
    "s2._grid = [\n",
    "  [BoxState.RED   , BoxState.EMPTY],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY]\n",
    "]\n",
    "s3 = deepcopy(s0)\n",
    "s3._grid = [\n",
    "  [BoxState.RED    , BoxState.YELLOW],\n",
    "  [BoxState.EMPTY  , BoxState.EMPTY ]\n",
    "]\n",
    "s4 = deepcopy(s0)\n",
    "s4._grid = [\n",
    "  [BoxState.RED    , BoxState.EMPTY ],\n",
    "  [BoxState.EMPTY  , BoxState.YELLOW]\n",
    "]\n",
    "\n",
    "print('Start state:')\n",
    "print(FourInARowRenderer(s0).render())\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = [s1, s2, s3, s4],\n",
    "  columns         = 8,\n",
    "  additional_info = lambda s: f'Action 0\\np: {round(env.get_transition_prob(0, s, s0), 2)}'\n",
    ")\n",
    "\n",
    "print('\\nNew state:')\n",
    "print(display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f161cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start state:\n",
      "┌───┬───┐\n",
      "│   │   │\n",
      "├───┼───┤\n",
      "│ R │ Y │\n",
      "└───┴───┘\n",
      "\n",
      "New state:\n",
      "┌───┬───┐ ┌───┬───┐\n",
      "│ R │   │ │ R │ Y │\n",
      "├───┼───┤ ├───┼───┤\n",
      "│ R │ Y │ │ R │ Y │\n",
      "└───┴───┘ └───┴───┘\n",
      " Action 0  Action 0\n",
      " p: 1.0    p: 0.0  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 2,\n",
    "  height        = 2,\n",
    "  win_condition = 2,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "s0 = deepcopy(env._state)\n",
    "s0._grid = [\n",
    "  [BoxState.RED   , BoxState.EMPTY ],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY ]\n",
    "]\n",
    "s1 = deepcopy(s0)\n",
    "s1._grid = [\n",
    "  [BoxState.RED   , BoxState.RED],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY ]\n",
    "]\n",
    "s2 = deepcopy(s0)\n",
    "s2._grid = [\n",
    "  [BoxState.RED   , BoxState.RED   ],\n",
    "  [BoxState.YELLOW, BoxState.YELLOW]\n",
    "]\n",
    "\n",
    "print('Start state:')\n",
    "print(FourInARowRenderer(s0).render())\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = [s1, s2],\n",
    "  columns         = 8,\n",
    "  additional_info = lambda s: f'Action 0\\np: {round(env.get_transition_prob(0, s, s0), 2)}'\n",
    ")\n",
    "\n",
    "print('\\nNew state:')\n",
    "print(display)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3b61a",
   "metadata": {},
   "source": [
    "### 3.3 Rewards\n",
    "\n",
    "The reward model is very basic. If the player wins the reward will result in 1 and if the opponent wins it results in a -1. For neutral states it will return 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4399d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards for player red:\n",
      "┌───┬───┐ ┌───┬───┐ ┌───┬───┐\n",
      "│   │   │ │ R │   │ │   │ Y │\n",
      "├───┼───┤ ├───┼───┤ ├───┼───┤\n",
      "│ R │ Y │ │ R │ Y │ │ R │ Y │\n",
      "└───┴───┘ └───┴───┘ └───┴───┘\n",
      " r: 0      r: 1      r: -1   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 2,\n",
    "  height        = 2,\n",
    "  win_condition = 2,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "s0 = deepcopy(env._state)\n",
    "s0._grid = [\n",
    "  [BoxState.RED   , BoxState.EMPTY ],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY ]\n",
    "]\n",
    "s1 = deepcopy(s0)\n",
    "s1._grid = [\n",
    "  [BoxState.RED   , BoxState.RED],\n",
    "  [BoxState.YELLOW, BoxState.EMPTY ]\n",
    "]\n",
    "s2 = deepcopy(s0)\n",
    "s2._grid = [\n",
    "  [BoxState.RED   , BoxState.EMPTY  ],\n",
    "  [BoxState.YELLOW, BoxState.YELLOW ]\n",
    "]\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states          = [s0, s1, s2],\n",
    "  columns         = 8,\n",
    "  additional_info = lambda s: f'r: {env.get_reward_for_state(s, Players.RED)}'\n",
    ")\n",
    "print('Rewards for player red:')\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d6e65",
   "metadata": {},
   "source": [
    "## 4 Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ff9b4",
   "metadata": {},
   "source": [
    "### 4.1 Random\n",
    "This agent will simply choose a valid action at random regardless of state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "833eb528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │   │   │   │ │ R │   │   │ │ R │   │ R │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │   │   │ │ Y │   │ R │ │ Y │   │ R │ │ Y │   │ R │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │ Y │   │ R │ │ Y │   │ R │ │ Y │ Y │ R │ │ Y │ Y │ R │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      "                                                                     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "\n",
    "agent = FourInARowRandomAgent(env)\n",
    "\n",
    "states = []\n",
    "states.append(deepcopy(env.get_state()))\n",
    "while not env.is_done():\n",
    "  env.step(agent.get_move())\n",
    "  states.append(deepcopy(env.get_state()))\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states = states,\n",
    "  columns = 8,\n",
    "  additional_info = lambda _: ''\n",
    ")\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d21b04",
   "metadata": {},
   "source": [
    "### 4.2 Semi-random\n",
    "This agent's policy is almost identical to the random agent's policy with one exception: it will look 1 step ahead. It will score if it is only one step away from winning, similarly it will block the opponent if they are one step away from winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24bdf729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │   │   │   │ │   │   │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │   │ Y │ │   │ Y │ Y │ │   │ Y │ Y │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │   │ R │ │   │ R │ R │ │ R │ R │ R │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      "                                                       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "\n",
    "agent = FourInARowSemiRandomAgent(env)\n",
    "\n",
    "states = []\n",
    "states.append(deepcopy(env.get_state()))\n",
    "while not env.is_done():\n",
    "  env.step(agent.get_move())\n",
    "  states.append(deepcopy(env.get_state()))\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states = states,\n",
    "  columns = 8,\n",
    "  additional_info = lambda _: ''\n",
    ")\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced42e1",
   "metadata": {},
   "source": [
    "### 4.3 Brute-force\n",
    "\n",
    "The brute-force agent will walk through all possibilities when making a move and returns the action that yields the highest reward. This will result in the best results but will not work for environments that could go on forever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b58ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │   │   │   │ │ R │   │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │   │   │ │ R │   │   │ │ R │   │   │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │ R │   │ Y │ │ R │ Y │ Y │ │ R │ Y │ Y │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      "                                                       \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "\n",
    "agent = FourInARowMinMaxAgent(env)\n",
    "\n",
    "states = []\n",
    "states.append(deepcopy(env.get_state()))\n",
    "while not env.is_done():\n",
    "  env.step(agent.get_move())\n",
    "  states.append(deepcopy(env.get_state()))\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states = states,\n",
    "  columns = 8,\n",
    "  additional_info = lambda _: ''\n",
    ")\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645f33c",
   "metadata": {},
   "source": [
    "### 4.4 Value Iteration\n",
    "\n",
    "The value iteration agent uses value iteration to solve Bellman's equation. It will compute the utility for every state at creation and will use it in the future to make decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b7fe6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐ ┌───┬───┬───┐\n",
      "│   │   │   │ │   │   │   │ │   │   │   │ │   │ R │   │ │   │ R │ Y │ │ R │ R │ Y │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │   │   │ │   │ R │   │ │ Y │ R │   │ │ Y │ R │ R │ │ Y │ R │ R │\n",
      "├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤ ├───┼───┼───┤\n",
      "│   │   │   │ │   │ Y │ R │ │ Y │ Y │ R │ │ Y │ Y │ R │ │ Y │ Y │ R │ │ Y │ Y │ R │\n",
      "└───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘ └───┴───┴───┘\n",
      "                                                                                   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = FourInARowEnv(\n",
    "  yellow_agent  = FourInARowRandomAgent,\n",
    "  width         = 3,\n",
    "  height        = 3,\n",
    "  win_condition = 3,\n",
    "  first_turn    = Players.RED\n",
    ")\n",
    "\n",
    "agent = FourInARowValueIterationAgent(env)\n",
    "\n",
    "states = []\n",
    "states.append(deepcopy(env.get_state()))\n",
    "while not env.is_done():\n",
    "  env.step(agent.get_move())\n",
    "  states.append(deepcopy(env.get_state()))\n",
    "\n",
    "display = render_multiple_states(\n",
    "  states = states,\n",
    "  columns = 8,\n",
    "  additional_info = lambda _: ''\n",
    ")\n",
    "print(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8225f",
   "metadata": {},
   "source": [
    "### 4.5 Preformance\n",
    "\n",
    "The matplotlib libary has been used to visualise the difference in preformance between several agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1bc30b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "agent_types = [FourInARowRandomAgent,FourInARowSemiRandomAgent] \n",
    "creator = FourInARowGraphCreator()\n",
    "creator.pref_graph()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1932237d5f6e1407a57ef8cc07d4a91480fed45ce28e9b3cad897d61089d0e1"
  },
  "kernelspec": {
   "display_name": "PyCharm (DecisionTheory)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "%load_ext autoreload\n",
     "%autoreload 2\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
